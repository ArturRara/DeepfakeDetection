{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from numpy.random import RandomState\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from models.MesoNet import MesoNet\n",
    "from data_loader import ImgDataset\n",
    "from torchvision.transforms import Normalize\n",
    "import torchvision.transforms as transforms\n",
    "from multiprocessing import Manager\n",
    "import data_preparation\n",
    "import importlib\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, device, best_acc,criterion,frames):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0.0\n",
    "    best_model = model.state_dict()\n",
    "\n",
    "    for batch, data in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            images = data[0]\n",
    "            labels = data[1]\n",
    "            tensor_shape = torch.Tensor(3*frames*val_loader.batch_size, images[0].shape[2], images[0].shape[3])\n",
    "            images = torch.cat(images, out=tensor_shape)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.view((-1,))\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.data.item()\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            val_corrects += torch.sum(preds == labels.data).to(torch.float32)\n",
    "            \n",
    "    epoch_loss = val_loss / len(val_loader.dataset) * frames\n",
    "    epoch_acc = val_corrects / len(val_loader.dataset) * frames\n",
    "        \n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model = model.state_dict()\n",
    "    return best_model,best_acc,epoch_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, model, optimizer, train_loader, val_loader, device,scheduler,frames=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_model = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    train_losses, val_losses, val_accuracy , train_accuracy= [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        model=model.train()\n",
    "        train_loss = 0.0\n",
    "        train_corrects = 0.0\n",
    "        \n",
    "        for batch, data in enumerate(train_loader):\n",
    "            print('butch nuber: ', batch)\n",
    "            iter_loss = 0.0\n",
    "            images = data[0]\n",
    "            labels = data[1]\n",
    "            tensor_shape = torch.Tensor(3*frames*train_loader.batch_size, images[0].shape[2], images[0].shape[3])\n",
    "            images = torch.cat(images, out=tensor_shape)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.view((-1,))  \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predictions  = model(images)\n",
    "            loss = criterion(predictions , labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            iter_loss = loss.data.item()\n",
    "            \n",
    "            train_loss += iter_loss\n",
    "            _, preds = torch.max(predictions.data, 1)\n",
    "            train_corrects += torch.sum(preds == labels.data).to(torch.float32)\n",
    "               \n",
    "        best_model, best_val_acc, val_epoch_loss = evaluate(model, val_loader, device, best_acc,criterion,frames)\n",
    "        train_epoch_loss = train_loss / len(train_loader.dataset) * frames\n",
    "        epoch_acc = train_corrects / len(train_loader.dataset) * frames\n",
    "        train_losses.append(train_epoch_loss) \n",
    "        val_losses.append(val_epoch_loss)\n",
    "        val_accuracy.append(best_val_acc)\n",
    "        train_accuracy.append(epoch_acc)\n",
    "        print('epoch train loss: ',val_epoch_loss )\n",
    "        print(\"epoch: %d\"%(epoch))\n",
    "        torch.save(model.state_dict(), \"state_dict/epoch\"+str(epoch)+\".pkl\")\n",
    "        scheduler.step() \n",
    "\n",
    "    torch.save(best_model, 'state_dict/best.pkl')\n",
    "    print(val_accuracy)\n",
    "    return train_losses ,val_losses ,train_accuracy ,val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots_losses(train_losses,val_losses,train_accuracy, val_accuracy):\n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(val_losses, label='Validation loss')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.savefig('loss.png')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(train_accuracy, label='Training accuracy')\n",
    "    plt.plot(val_accuracy, label='Validation accuracy')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.savefig('accuracy.png')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(path=r'C:\\Users\\artur\\Downloads\\faceforensics_frames\\metadata.csv',frames=10):\n",
    "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\ttorch.backends.cudnn.benchmark=True\n",
    "\t\n",
    "\tmetadata = pd.read_csv(path)\n",
    "\trng = RandomState()\n",
    "\ttrain_df = metadata.sample(frac=0.8, random_state=rng)\n",
    "\ttest_df = metadata.loc[~metadata.index.isin(train_df.index)]\n",
    "\t\n",
    "\ttrain_data = ImgDataset(train_df,emotion='Normal',transform = \"Harshil_Albumentations\",frames=10)\n",
    "\tval_data = ImgDataset(test_df)\n",
    "\ttrain_loader = DataLoader(train_data, batch_size=16, shuffle=True) \n",
    "\tval_loader = DataLoader(val_data, batch_size=16, shuffle=True)\n",
    "\ttrain_dataset_size = len(train_df)  \n",
    "\tval_dataset_size = len(test_df)\n",
    "\n",
    "\tmodel = MesoNet()\n",
    "\tmodel = model.to(device)\n",
    "\toptimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999)) #, eps=1e-08\n",
    "\tscheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\tdir_path = os.path.abspath('')\n",
    "\tif not os.path.exists(os.path.join(dir_path,\"state_dict\")):\n",
    "\t\tos.mkdir(os.path.join(dir_path,\"state_dict\"))\n",
    "\ttrain_losses,val_losses,train_accuracy, val_accuracy = train(8, model, optimizer, train_loader, val_loader, device, scheduler, frames)\n",
    "\tprint(train_accuracy,val_accuracy)\n",
    "\tprint(train_losses,val_losses)\n",
    "\tplots_losses(train_losses,val_losses,train_accuracy,val_accuracy )\n",
    "\t\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(path=r'C:\\Users\\artur\\Downloads\\faceforensics_frames\\metadata.csv',frames=10):\n",
    "\tmodel = MesoNet()\n",
    "\tmodel.load_state_dict(torch.load(r'.\\state_dict\\best.pkl'))\n",
    "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\ttest_corrects = 0\n",
    "\tacc = 0\n",
    "\tmetadata = pd.read_csv(path)\n",
    "\ttest_dataset = ImgDataset(metadata,frames)\n",
    "\ttest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "\tprint(len(metadata), \"videos\")\n",
    "\twith torch.no_grad():\n",
    "\t\tfor batch, data in enumerate(test_loader):\n",
    "\t\t\timages = data[0]\n",
    "\t\t\tlabels = data[1]\n",
    "\t\t\ttensor_shape = torch.Tensor(3*frames*test_loader.batch_size, images[0].shape[2], images[0].shape[3])\n",
    "\t\t\timages = torch.cat(images, out=tensor_shape)\n",
    "\t\t\timages = images.to(device)\n",
    "\t\t\tlabels = labels.to(device)\n",
    "\t\t\tlabels = labels.view((-1,))\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\t_, preds = torch.max(outputs.data, 1)\n",
    "\t\t\ttest_corrects += torch.sum(preds == labels.data).to(torch.float32)\n",
    "\t\tprint('Accuracy {:.4f}'.format(torch.sum(preds == labels.data).to(torch.float32)/len(test_loader.dataset) * frames))\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f1b78eb436411a9c3c2406ff65dd6a2a483e2b78ec2ae8c1343ef3e593983b6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
